# Mamba: Linear Time Sequence Modeling with Selective State Spaces
[Paper](https://arxiv.org/abs/2312.00752)

## Abstract
- Subquadratic-time architecutes such as linear attention, gated convolution and recurrent models, 
and structured state space models (SSMs) have been developed to address the computational 
inefficiency of transformers but they have not performed as well on modalities such as language.
